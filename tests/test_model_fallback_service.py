"""
AuraWell å¤šæ¨¡å‹æ¢¯åº¦æœåŠ¡æµ‹è¯•
æµ‹è¯•deepseek-r1-0528å’Œqwen-turboçš„æ™ºèƒ½åˆ‡æ¢æœºåˆ¶
"""

import unittest
import pytest
import logging
import os
import sys
import asyncio
from unittest.mock import Mock, patch, AsyncMock
import time

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'src'))

from aurawell.services.model_fallback_service import (
    ModelFallbackService, 
    ModelTier, 
    ModelConfig, 
    ModelResponse,
    get_model_fallback_service
)

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class TestModelFallbackService(unittest.TestCase):
    """å¤šæ¨¡å‹æ¢¯åº¦æœåŠ¡æµ‹è¯•ç±»"""
    
    def setUp(self):
        """æµ‹è¯•å‰å‡†å¤‡"""
        self.mock_deepseek_client = Mock()
        self.service = ModelFallbackService(self.mock_deepseek_client)
    
    def test_service_initialization(self):
        """æµ‹è¯•æœåŠ¡åˆå§‹åŒ–"""
        logger.info("ğŸ§ª æµ‹è¯•å¤šæ¨¡å‹æ¢¯åº¦æœåŠ¡åˆå§‹åŒ–")
        
        # éªŒè¯æ¨¡å‹é…ç½®
        self.assertIn(ModelTier.HIGH_PRECISION, self.service.model_configs)
        self.assertIn(ModelTier.FAST_RESPONSE, self.service.model_configs)
        
        # éªŒè¯é«˜ç²¾åº¦æ¨¡å‹é…ç½®
        high_precision_config = self.service.model_configs[ModelTier.HIGH_PRECISION]
        self.assertEqual(high_precision_config.name, "deepseek-r1-0528")
        self.assertEqual(high_precision_config.timeout_threshold, 180.0)
        
        # éªŒè¯å¿«é€Ÿå“åº”æ¨¡å‹é…ç½®
        fast_response_config = self.service.model_configs[ModelTier.FAST_RESPONSE]
        self.assertEqual(fast_response_config.name, "qwen-turbo")
        self.assertEqual(fast_response_config.timeout_threshold, 60.0)
        
        # éªŒè¯æ€§èƒ½ç»Ÿè®¡åˆå§‹åŒ–
        self.assertIn(ModelTier.HIGH_PRECISION, self.service.performance_stats)
        self.assertIn(ModelTier.FAST_RESPONSE, self.service.performance_stats)
        
        logger.info("âœ… å¤šæ¨¡å‹æ¢¯åº¦æœåŠ¡åˆå§‹åŒ–æµ‹è¯•é€šè¿‡")
    
    def test_performance_stats_update(self):
        """æµ‹è¯•æ€§èƒ½ç»Ÿè®¡æ›´æ–°"""
        logger.info("ğŸ§ª æµ‹è¯•æ€§èƒ½ç»Ÿè®¡æ›´æ–°")
        
        # æµ‹è¯•æˆåŠŸè°ƒç”¨ç»Ÿè®¡
        self.service._update_performance_stats(ModelTier.HIGH_PRECISION, 2.5, True)
        
        stats = self.service.performance_stats[ModelTier.HIGH_PRECISION]
        self.assertEqual(stats["total_calls"], 1)
        self.assertEqual(stats["successful_calls"], 1)
        self.assertEqual(stats["average_response_time"], 2.5)
        self.assertEqual(stats["timeout_count"], 0)
        
        # æµ‹è¯•è¶…æ—¶è°ƒç”¨ç»Ÿè®¡
        self.service._update_performance_stats(ModelTier.HIGH_PRECISION, 5.0, False, timeout=True)
        
        stats = self.service.performance_stats[ModelTier.HIGH_PRECISION]
        self.assertEqual(stats["total_calls"], 2)
        self.assertEqual(stats["successful_calls"], 1)
        self.assertEqual(stats["timeout_count"], 1)
        
        logger.info("âœ… æ€§èƒ½ç»Ÿè®¡æ›´æ–°æµ‹è¯•é€šè¿‡")
    
    def test_should_fallback_logic(self):
        """æµ‹è¯•é™çº§é€»è¾‘"""
        logger.info("ğŸ§ª æµ‹è¯•é™çº§é€»è¾‘")
        
        # åˆå§‹çŠ¶æ€ä¸åº”è¯¥é™çº§
        should_fallback = self.service._should_fallback_to_fast_model(ModelTier.HIGH_PRECISION)
        self.assertFalse(should_fallback)
        
        # æ¨¡æ‹Ÿé«˜è¶…æ—¶ç‡æƒ…å†µ
        for _ in range(10):
            self.service._update_performance_stats(ModelTier.HIGH_PRECISION, 5.0, False, timeout=True)
        
        should_fallback = self.service._should_fallback_to_fast_model(ModelTier.HIGH_PRECISION)
        self.assertTrue(should_fallback)
        
        # é‡ç½®ç»Ÿè®¡
        self.service.performance_stats[ModelTier.HIGH_PRECISION] = {
            "total_calls": 0,
            "successful_calls": 0,
            "average_response_time": 0.0,
            "timeout_count": 0
        }
        
        # æ¨¡æ‹Ÿé«˜å“åº”æ—¶é—´æƒ…å†µ
        for _ in range(5):
            self.service._update_performance_stats(ModelTier.HIGH_PRECISION, 150.0, True)
        
        should_fallback = self.service._should_fallback_to_fast_model(ModelTier.HIGH_PRECISION)
        self.assertTrue(should_fallback)
        
        logger.info("âœ… é™çº§é€»è¾‘æµ‹è¯•é€šè¿‡")
    
    def test_context_preservation(self):
        """æµ‹è¯•ä¸Šä¸‹æ–‡ä¿å­˜"""
        logger.info("ğŸ§ª æµ‹è¯•ä¸Šä¸‹æ–‡ä¿å­˜")
        
        conversation_id = "test_conv_123"
        
        # ä¿å­˜ç¬¬ä¸€è½®å¯¹è¯
        self.service._preserve_context(
            conversation_id, 
            "ä½ å¥½", 
            "æ‚¨å¥½ï¼æˆ‘æ˜¯å¥åº·åŠ©æ‰‹", 
            "deepseek-r1-0528"
        )
        
        # éªŒè¯ä¸Šä¸‹æ–‡ä¿å­˜
        self.assertIn(conversation_id, self.service.conversation_context)
        context = self.service.conversation_context[conversation_id]
        self.assertEqual(len(context), 1)
        self.assertEqual(context[0]["user"], "ä½ å¥½")
        self.assertEqual(context[0]["assistant"], "æ‚¨å¥½ï¼æˆ‘æ˜¯å¥åº·åŠ©æ‰‹")
        self.assertEqual(context[0]["model"], "deepseek-r1-0528")
        
        # ä¿å­˜æ›´å¤šå¯¹è¯ï¼Œæµ‹è¯•é•¿åº¦é™åˆ¶
        for i in range(10):
            self.service._preserve_context(
                conversation_id,
                f"é—®é¢˜{i}",
                f"å›ç­”{i}",
                "qwen-turbo"
            )
        
        # éªŒè¯åªä¿ç•™æœ€è¿‘5è½®å¯¹è¯
        context = self.service.conversation_context[conversation_id]
        self.assertEqual(len(context), 5)
        
        logger.info("âœ… ä¸Šä¸‹æ–‡ä¿å­˜æµ‹è¯•é€šè¿‡")
    
    def test_build_messages_with_context(self):
        """æµ‹è¯•æ„å»ºåŒ…å«ä¸Šä¸‹æ–‡çš„æ¶ˆæ¯"""
        logger.info("ğŸ§ª æµ‹è¯•æ„å»ºåŒ…å«ä¸Šä¸‹æ–‡çš„æ¶ˆæ¯")
        
        conversation_id = "test_conv_456"
        
        # ä¿å­˜ä¸€äº›ä¸Šä¸‹æ–‡
        self.service._preserve_context(conversation_id, "ä¹‹å‰çš„é—®é¢˜", "ä¹‹å‰çš„å›ç­”", "deepseek-r1-0528")
        
        # æ„å»ºæ¶ˆæ¯
        messages = [
            {"role": "system", "content": "ä½ æ˜¯å¥åº·åŠ©æ‰‹"},
            {"role": "user", "content": "å½“å‰é—®é¢˜"}
        ]
        
        enhanced_messages = self.service._build_messages_with_context(messages, conversation_id)
        
        # éªŒè¯æ¶ˆæ¯ç»“æ„
        self.assertGreater(len(enhanced_messages), len(messages))
        
        # éªŒè¯åŒ…å«ç³»ç»Ÿæ¶ˆæ¯
        system_messages = [msg for msg in enhanced_messages if msg["role"] == "system"]
        self.assertEqual(len(system_messages), 1)
        
        # éªŒè¯åŒ…å«ä¸Šä¸‹æ–‡
        context_found = any("ä¹‹å‰çš„é—®é¢˜" in msg["content"] for msg in enhanced_messages if msg["role"] == "user")
        self.assertTrue(context_found)
        
        logger.info("âœ… æ„å»ºåŒ…å«ä¸Šä¸‹æ–‡çš„æ¶ˆæ¯æµ‹è¯•é€šè¿‡")
    
    @pytest.mark.asyncio
    async def test_successful_model_response(self):
        """æµ‹è¯•æˆåŠŸçš„æ¨¡å‹å“åº”"""
        logger.info("ğŸ§ª æµ‹è¯•æˆåŠŸçš„æ¨¡å‹å“åº”")
        
        # MockæˆåŠŸçš„DeepSeekå“åº”
        mock_response = Mock()
        mock_response.content = "è¿™æ˜¯ä¸€ä¸ªå¥åº·å»ºè®®"
        self.mock_deepseek_client.get_deepseek_response.return_value = mock_response
        
        messages = [{"role": "user", "content": "ç»™æˆ‘ä¸€äº›å¥åº·å»ºè®®"}]
        
        result = await self.service.get_model_response(messages)
        
        # éªŒè¯å“åº”
        self.assertTrue(result.success)
        self.assertEqual(result.content, "è¿™æ˜¯ä¸€ä¸ªå¥åº·å»ºè®®")
        self.assertEqual(result.model_used, "deepseek-r1-0528")
        self.assertGreater(result.response_time, 0)
        
        logger.info("âœ… æˆåŠŸçš„æ¨¡å‹å“åº”æµ‹è¯•é€šè¿‡")
    
    @pytest.mark.asyncio
    async def test_model_timeout_fallback(self):
        """æµ‹è¯•æ¨¡å‹è¶…æ—¶é™çº§"""
        logger.info("ğŸ§ª æµ‹è¯•æ¨¡å‹è¶…æ—¶é™çº§")
        
        # Mockç¬¬ä¸€ä¸ªæ¨¡å‹è¶…æ—¶ï¼Œç¬¬äºŒä¸ªæ¨¡å‹æˆåŠŸ
        async def mock_call_model(config, messages, temperature, max_tokens, **kwargs):
            if config.name == "deepseek-r1-0528":
                await asyncio.sleep(0.1)  # æ¨¡æ‹Ÿè¶…æ—¶
                raise asyncio.TimeoutError("æ¨¡å‹å“åº”è¶…æ—¶")
            else:
                mock_response = Mock()
                mock_response.content = "å¿«é€Ÿå“åº”å†…å®¹"
                return mock_response
        
        self.service._call_model = mock_call_model
        
        # è®¾ç½®è¾ƒçŸ­çš„è¶…æ—¶æ—¶é—´ç”¨äºæµ‹è¯•
        self.service.model_configs[ModelTier.HIGH_PRECISION].timeout_threshold = 0.05
        
        messages = [{"role": "user", "content": "æµ‹è¯•è¶…æ—¶"}]
        
        result = await self.service.get_model_response(messages)
        
        # éªŒè¯é™çº§åˆ°å¿«é€Ÿæ¨¡å‹
        self.assertTrue(result.success)
        self.assertEqual(result.content, "å¿«é€Ÿå“åº”å†…å®¹")
        self.assertEqual(result.model_used, "qwen-turbo")
        
        logger.info("âœ… æ¨¡å‹è¶…æ—¶é™çº§æµ‹è¯•é€šè¿‡")
    
    @pytest.mark.asyncio
    async def test_all_models_fail(self):
        """æµ‹è¯•æ‰€æœ‰æ¨¡å‹éƒ½å¤±è´¥çš„æƒ…å†µ"""
        logger.info("ğŸ§ª æµ‹è¯•æ‰€æœ‰æ¨¡å‹éƒ½å¤±è´¥çš„æƒ…å†µ")
        
        # Mockæ‰€æœ‰æ¨¡å‹éƒ½å¤±è´¥
        async def mock_call_model_fail(config, messages, temperature, max_tokens, **kwargs):
            raise Exception(f"æ¨¡å‹ {config.name} è°ƒç”¨å¤±è´¥")
        
        self.service._call_model = mock_call_model_fail
        
        messages = [{"role": "user", "content": "æµ‹è¯•å¤±è´¥"}]
        
        result = await self.service.get_model_response(messages)
        
        # éªŒè¯å¤±è´¥å“åº”
        self.assertFalse(result.success)
        self.assertIn("æŠ±æ­‰", result.content)
        self.assertEqual(result.model_used, "none")
        self.assertIsNotNone(result.error_message)
        
        logger.info("âœ… æ‰€æœ‰æ¨¡å‹éƒ½å¤±è´¥çš„æƒ…å†µæµ‹è¯•é€šè¿‡")
    
    def test_performance_report(self):
        """æµ‹è¯•æ€§èƒ½æŠ¥å‘Š"""
        logger.info("ğŸ§ª æµ‹è¯•æ€§èƒ½æŠ¥å‘Š")
        
        # æ·»åŠ ä¸€äº›ç»Ÿè®¡æ•°æ®
        self.service._update_performance_stats(ModelTier.HIGH_PRECISION, 2.0, True)
        self.service._update_performance_stats(ModelTier.FAST_RESPONSE, 1.0, True)
        
        report = self.service.get_performance_report()
        
        # éªŒè¯æŠ¥å‘Šç»“æ„
        self.assertIn("model_configs", report)
        self.assertIn("performance_stats", report)
        self.assertIn("active_conversations", report)
        
        # éªŒè¯æ¨¡å‹é…ç½®ä¿¡æ¯
        self.assertIn("HighPrecision", report["model_configs"])
        self.assertIn("FastResponse", report["model_configs"])
        
        # éªŒè¯æ€§èƒ½ç»Ÿè®¡ä¿¡æ¯
        self.assertIn("HighPrecision", report["performance_stats"])
        self.assertIn("FastResponse", report["performance_stats"])
        
        logger.info("âœ… æ€§èƒ½æŠ¥å‘Šæµ‹è¯•é€šè¿‡")
    
    def test_singleton_pattern(self):
        """æµ‹è¯•å•ä¾‹æ¨¡å¼"""
        logger.info("ğŸ§ª æµ‹è¯•å•ä¾‹æ¨¡å¼")
        
        # æ¸…é™¤å…¨å±€å®ä¾‹
        import aurawell.services.model_fallback_service as mfs_module
        mfs_module._model_fallback_service = None
        
        service1 = get_model_fallback_service(self.mock_deepseek_client)
        service2 = get_model_fallback_service(self.mock_deepseek_client)
        
        self.assertIs(service1, service2, "å•ä¾‹æ¨¡å¼å¤±è´¥")
        
        logger.info("âœ… å•ä¾‹æ¨¡å¼æµ‹è¯•é€šè¿‡")


class TestModelFallbackIntegration(unittest.TestCase):
    """å¤šæ¨¡å‹æ¢¯åº¦æœåŠ¡é›†æˆæµ‹è¯•"""
    
    @pytest.mark.integration
    def test_chat_service_integration(self):
        """æµ‹è¯•ä¸èŠå¤©æœåŠ¡çš„é›†æˆ"""
        logger.info("ğŸ§ª æµ‹è¯•ä¸èŠå¤©æœåŠ¡çš„é›†æˆ")
        
        try:
            from aurawell.services.chat_service import ChatService
            
            chat_service = ChatService()
            
            # éªŒè¯å¤šæ¨¡å‹æœåŠ¡å·²é›†æˆ
            self.assertIsNotNone(chat_service.model_fallback_service)
            
            logger.info("âœ… ä¸èŠå¤©æœåŠ¡çš„é›†æˆæµ‹è¯•é€šè¿‡")
            
        except Exception as e:
            logger.warning(f"âš ï¸ èŠå¤©æœåŠ¡é›†æˆæµ‹è¯•è·³è¿‡: {e}")
            pytest.skip("èŠå¤©æœåŠ¡ä¸å¯ç”¨")


if __name__ == '__main__':
    # è¿è¡Œæµ‹è¯•
    unittest.main(verbosity=2)
