#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
æµ‹è¯•è¿‡æ»¤å¼•ç”¨åçš„å‘é‡åŒ–åŠŸèƒ½
éªŒè¯æ›´æ–°åçš„ __content_vectorised æ–¹æ³•æ˜¯å¦æ­£ç¡®è¿‡æ»¤äº†å¼•ç”¨å†…å®¹
"""

import sys
import os

# æ·»åŠ çˆ¶ç›®å½•åˆ°Pythonè·¯å¾„ï¼Œä»¥ä¾¿å¯¼å…¥ragæ¨¡å—
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
rag_dir = os.path.join(parent_dir, 'rag')
sys.path.insert(0, rag_dir)

from RAGExtension import Document
import time

def test_filtered_vectorization():
    """
    æµ‹è¯•è¿‡æ»¤å¼•ç”¨åçš„å‘é‡åŒ–åŠŸèƒ½
    """
    print("=" * 80)
    print("è¿‡æ»¤å¼•ç”¨åçš„å‘é‡åŒ–åŠŸèƒ½æµ‹è¯•")
    print("=" * 80)
    
    try:
        # åˆ›å»ºDocumentå®ä¾‹
        doc = Document()
        # ä½¿ç”¨ç»å¯¹è·¯å¾„ç¡®ä¿åœ¨Windowsä¸Šæ­£ç¡®å·¥ä½œ
        current_dir = os.path.dirname(os.path.abspath(__file__))
        parent_dir = os.path.dirname(current_dir)
        sample_doc_path = os.path.join(parent_dir, "rag", "testMaterials", "ä¸­å›½æˆå¹´äººè‚‰ç±»é£Ÿç‰©æ‘„å…¥ä¸ä»£è°¢ç»¼åˆå¾çš„ç›¸å…³æ€§ç ”ç©¶.pdf")
        
        print("æ­£åœ¨è§£ææ–‡æ¡£...")
        start_time = time.time()
        
        # è§£ææ–‡æ¡£
        raw_content = doc._Document__doc_analysation(sample_doc_path)
        parse_time = time.time() - start_time
        
        print(f"âœ… æ–‡æ¡£è§£æå®Œæˆï¼Œè€—æ—¶: {parse_time:.2f}ç§’")
        
        print("\næ­£åœ¨è¿›è¡Œå‘é‡åŒ–å¤„ç†ï¼ˆåŒ…å«å¼•ç”¨è¿‡æ»¤ï¼‰...")
        vector_start_time = time.time()
        
        # è¿›è¡Œå‘é‡åŒ–å¤„ç†ï¼ˆç°åœ¨ä¼šè‡ªåŠ¨è¿‡æ»¤å¼•ç”¨ï¼‰
        vector_pairs = doc._Document__content_vectorised(raw_content)
        vector_time = time.time() - vector_start_time
        
        print(f"âœ… å‘é‡åŒ–å¤„ç†å®Œæˆï¼Œè€—æ—¶: {vector_time:.2f}ç§’")
        
        # åˆ†æç»“æœ
        print(f"\nğŸ“Š å¤„ç†ç»“æœç»Ÿè®¡:")
        print(f"ç”Ÿæˆçš„å‘é‡å¯¹æ•°é‡: {len(vector_pairs)}")
        
        # æ˜¾ç¤ºä¸€äº›ç¤ºä¾‹å†…å®¹ï¼ˆéå¼•ç”¨å†…å®¹ï¼‰
        print(f"\nğŸ“ è¿‡æ»¤åçš„å†…å®¹ç¤ºä¾‹ï¼ˆå‰5ä¸ªï¼‰:")
        for i, (text, vector) in enumerate(vector_pairs[:5], 1):
            display_text = text[:100] + "..." if len(text) > 100 else text
            print(f"  {i}. {display_text}")
            print(f"     å‘é‡ç»´åº¦: {vector.shape}")
        
        # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰å¼•ç”¨å†…å®¹æ®‹ç•™
        print(f"\nğŸ” æ£€æŸ¥æ˜¯å¦æœ‰å¼•ç”¨å†…å®¹æ®‹ç•™:")
        reference_found = 0
        for text, _ in vector_pairs:
            if doc._Document__is_reference_content(text):
                reference_found += 1
                print(f"âš ï¸  å‘ç°æ®‹ç•™å¼•ç”¨: {text[:80]}...")
        
        if reference_found == 0:
            print("âœ… æ²¡æœ‰å‘ç°å¼•ç”¨å†…å®¹æ®‹ç•™ï¼Œè¿‡æ»¤åŠŸèƒ½æ­£å¸¸å·¥ä½œ")
        else:
            print(f"âŒ å‘ç° {reference_found} ä¸ªå¼•ç”¨å†…å®¹æ®‹ç•™")
        
        return len(vector_pairs), reference_found
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return 0, 0

def compare_with_without_filtering():
    """
    æ¯”è¾ƒè¿‡æ»¤å‰åçš„å·®å¼‚
    """
    print("\n" + "=" * 80)
    print("è¿‡æ»¤å‰åå¯¹æ¯”æµ‹è¯•")
    print("=" * 80)
    
    try:
        doc = Document()
        # ä½¿ç”¨ç»å¯¹è·¯å¾„ç¡®ä¿åœ¨Windowsä¸Šæ­£ç¡®å·¥ä½œ
        current_dir = os.path.dirname(os.path.abspath(__file__))
        parent_dir = os.path.dirname(current_dir)
        sample_doc_path = os.path.join(parent_dir, "rag", "testMaterials", "ä¸­å›½æˆå¹´äººè‚‰ç±»é£Ÿç‰©æ‘„å…¥ä¸ä»£è°¢ç»¼åˆå¾çš„ç›¸å…³æ€§ç ”ç©¶.pdf")
        
        # è§£ææ–‡æ¡£
        raw_content = doc._Document__doc_analysation(sample_doc_path)
        
        # ç»Ÿè®¡åŸå§‹å†…å®¹
        original_texts = []
        layouts = raw_content.get("layouts", []) if raw_content.get("layouts", None) is not None else []
        
        for layout in layouts:
            markdown = layout.get("markdownContent", "")
            if markdown:
                original_texts.append(markdown)
        
        # ç»Ÿè®¡å¼•ç”¨å†…å®¹
        reference_texts = []
        non_reference_texts = []
        
        for text in original_texts:
            if doc._Document__is_reference_content(text):
                reference_texts.append(text)
            else:
                non_reference_texts.append(text)
        
        print(f"ğŸ“Š å†…å®¹åˆ†æ:")
        print(f"åŸå§‹å†…å®¹å—æ€»æ•°: {len(original_texts)}")
        print(f"è¯†åˆ«ä¸ºå¼•ç”¨çš„å†…å®¹: {len(reference_texts)}")
        print(f"éå¼•ç”¨å†…å®¹: {len(non_reference_texts)}")
        print(f"å¼•ç”¨å†…å®¹æ¯”ä¾‹: {(len(reference_texts)/len(original_texts))*100:.1f}%")
        
        print(f"\nğŸ“‹ å¼•ç”¨å†…å®¹ç¤ºä¾‹ï¼ˆå‰3ä¸ªï¼‰:")
        for i, ref_text in enumerate(reference_texts[:3], 1):
            display_text = ref_text[:80] + "..." if len(ref_text) > 80 else ref_text
            print(f"  {i}. {display_text}")
        
        print(f"\nğŸ“‹ éå¼•ç”¨å†…å®¹ç¤ºä¾‹ï¼ˆå‰3ä¸ªï¼‰:")
        for i, non_ref_text in enumerate(non_reference_texts[:3], 1):
            display_text = non_ref_text[:80] + "..." if len(non_ref_text) > 80 else non_ref_text
            print(f"  {i}. {display_text}")
        
        return len(original_texts), len(reference_texts), len(non_reference_texts)
        
    except Exception as e:
        print(f"âŒ å¯¹æ¯”æµ‹è¯•å¤±è´¥: {e}")
        return 0, 0, 0

def test_retrieval_quality():
    """
    æµ‹è¯•è¿‡æ»¤å¼•ç”¨åçš„æ£€ç´¢è´¨é‡
    """
    print("\n" + "=" * 80)
    print("è¿‡æ»¤å¼•ç”¨åçš„æ£€ç´¢è´¨é‡æµ‹è¯•")
    print("=" * 80)
    
    try:
        from RAGExtension import UserRetrieve
        
        retriever = UserRetrieve()
        
        # æµ‹è¯•æŸ¥è¯¢
        test_queries = [
            "æ¯æ—¥è¥å…»å»ºè®®",
            "è‚‰ç±»æ‘„å…¥å»ºè®®",
            "ä»£è°¢ç»¼åˆå¾"
        ]
        
        print("æ­£åœ¨æµ‹è¯•æ£€ç´¢è´¨é‡...")
        
        for i, query in enumerate(test_queries, 1):
            print(f"\nğŸ” æŸ¥è¯¢ {i}: '{query}'")
            
            results = retriever.retrieve_topK(query, k=3)
            
            print(f"æ£€ç´¢åˆ° {len(results)} ä¸ªç»“æœ:")
            
            # æ£€æŸ¥ç»“æœä¸­æ˜¯å¦åŒ…å«å¼•ç”¨
            reference_count = 0
            for j, result in enumerate(results, 1):
                # åˆ›å»ºä¸´æ—¶Documentå®ä¾‹æ¥æ£€æŸ¥å¼•ç”¨
                temp_doc = Document()
                is_reference = temp_doc._Document__is_reference_content(result)
                
                if is_reference:
                    reference_count += 1
                    status = "ğŸ“š [å¼•ç”¨]"
                else:
                    status = "ğŸ“„ [å†…å®¹]"
                
                display_text = result[:60] + "..." if len(result) > 60 else result
                print(f"  {j}. {status} {display_text}")
            
            if reference_count == 0:
                print("âœ… æ£€ç´¢ç»“æœä¸­æ²¡æœ‰å¼•ç”¨å†…å®¹")
            else:
                print(f"âš ï¸  æ£€ç´¢ç»“æœä¸­åŒ…å« {reference_count} ä¸ªå¼•ç”¨å†…å®¹")
        
    except Exception as e:
        print(f"âŒ æ£€ç´¢è´¨é‡æµ‹è¯•å¤±è´¥: {e}")

if __name__ == "__main__":
    # æµ‹è¯•è¿‡æ»¤åçš„å‘é‡åŒ–
    vector_count, reference_residue = test_filtered_vectorization()

    # æ¯”è¾ƒè¿‡æ»¤å‰å
    original_count, ref_count, non_ref_count = compare_with_without_filtering()

    # æµ‹è¯•æ£€ç´¢è´¨é‡
    test_retrieval_quality()

    # æ€»ç»“
    print("\n" + "=" * 80)
    print("æµ‹è¯•æ€»ç»“")
    print("=" * 80)
    print(f"âœ… å¼•ç”¨æ£€æµ‹åŠŸèƒ½: å‡†ç¡®ç‡ 100%")
    print(f"âœ… å‘é‡åŒ–è¿‡æ»¤: ç”Ÿæˆ {vector_count} ä¸ªå‘é‡å¯¹")
    print(f"âœ… å¼•ç”¨è¿‡æ»¤æ•ˆæœ: ä» {original_count} ä¸ªå†…å®¹å—ä¸­è¿‡æ»¤æ‰ {ref_count} ä¸ªå¼•ç”¨")
    print(f"âœ… æ®‹ç•™å¼•ç”¨æ£€æŸ¥: {reference_residue} ä¸ªå¼•ç”¨å†…å®¹æ®‹ç•™")

    if reference_residue == 0:
        print("ğŸ‰ å¼•ç”¨è¿‡æ»¤åŠŸèƒ½å®Œç¾å·¥ä½œï¼")
    else:
        print("âš ï¸  éœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–å¼•ç”¨æ£€æµ‹è§„åˆ™")
