#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
RAG æ£€ç´¢åŠŸèƒ½åˆ†ææŠ¥å‘Š
åˆ†ææ£€ç´¢ç»“æœçš„è´¨é‡å’Œç›¸å…³æ€§
"""

import sys
import os

# æ·»åŠ çˆ¶ç›®å½•åˆ°Pythonè·¯å¾„ï¼Œä»¥ä¾¿å¯¼å…¥ragæ¨¡å—
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
rag_dir = os.path.join(parent_dir, 'rag')
sys.path.insert(0, rag_dir)

from RAGExtension import UserRetrieve
import time

def analyze_retrieval_quality():
    """
    åˆ†ææ£€ç´¢è´¨é‡å’Œç›¸å…³æ€§
    """
    print("=" * 80)
    print("RAG æ£€ç´¢åŠŸèƒ½è´¨é‡åˆ†ææŠ¥å‘Š")
    print("=" * 80)
    
    retriever = UserRetrieve()
    
    # æµ‹è¯•æŸ¥è¯¢å’ŒæœŸæœ›å…³é”®è¯
    test_cases = [
        {
            "query": "æ¯æ—¥è¥å…»å»ºè®®",
            "expected_keywords": ["è¥å…»", "è†³é£Ÿ", "é£Ÿç‰©", "æ‘„å…¥", "æ¯å¤©", "å»ºè®®"],
            "description": "ç”¨æˆ·è¯¢é—®æ—¥å¸¸è¥å…»æ‘„å…¥å»ºè®®"
        },
        {
            "query": "è¿åŠ¨åçš„è¥å…»è¡¥å……å»ºè®®", 
            "expected_keywords": ["è¿åŠ¨", "è¡¥å……", "æ°´", "é¥®æ–™", "èƒ½é‡", "æ¢å¤"],
            "description": "ç”¨æˆ·è¯¢é—®è¿åŠ¨åå¦‚ä½•è¡¥å……è¥å…»"
        },
        {
            "query": "é«˜è¡€å‹é«˜è¡€è„‚çš„é¥®é£Ÿå»ºè®®",
            "expected_keywords": ["è¡€å‹", "è¡€è„‚", "ç›", "æ²¹", "æ¸…æ·¡", "æ§åˆ¶"],
            "description": "ç”¨æˆ·è¯¢é—®å¿ƒè¡€ç®¡ç–¾ç—…çš„é¥®é£ŸæŒ‡å¯¼"
        }
    ]
    
    overall_results = []
    
    for i, test_case in enumerate(test_cases, 1):
        print(f"\nğŸ“Š æµ‹è¯•æ¡ˆä¾‹ {i}: {test_case['description']}")
        print(f"ğŸ” æŸ¥è¯¢: '{test_case['query']}'")
        print(f"ğŸ¯ æœŸæœ›å…³é”®è¯: {test_case['expected_keywords']}")
        print("-" * 60)
        
        try:
            start_time = time.time()
            results = retriever.retrieve_topK(test_case['query'], k=5)
            end_time = time.time()
            
            # åˆ†æç»“æœè´¨é‡
            analysis = analyze_results(results, test_case['expected_keywords'])
            analysis['query'] = test_case['query']
            analysis['response_time'] = end_time - start_time
            overall_results.append(analysis)
            
            print(f"â±ï¸  å“åº”æ—¶é—´: {analysis['response_time']:.2f}ç§’")
            print(f"ğŸ“ˆ ç›¸å…³æ€§è¯„åˆ†: {analysis['relevance_score']:.1f}/10")
            print(f"ğŸ¯ å…³é”®è¯åŒ¹é…ç‡: {analysis['keyword_match_rate']:.1f}%")
            print(f"ğŸ“ æ£€ç´¢åˆ°çš„å­—æ®µæ•°: {analysis['total_results']}")
            
            print(f"\nğŸ“‹ æ£€ç´¢ç»“æœè¯¦æƒ…:")
            for j, (result, score) in enumerate(zip(results, analysis['individual_scores']), 1):
                print(f"  {j}. [ç›¸å…³æ€§: {score:.1f}/10] {result[:100]}{'...' if len(result) > 100 else ''}")
            
            if analysis['matched_keywords']:
                print(f"\nâœ… åŒ¹é…çš„å…³é”®è¯: {analysis['matched_keywords']}")
            if analysis['missing_keywords']:
                print(f"âŒ æœªåŒ¹é…çš„å…³é”®è¯: {analysis['missing_keywords']}")
                
        except Exception as e:
            print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
            
        print("\n" + "=" * 60)
        
        # æ·»åŠ å»¶è¿Ÿ
        if i < len(test_cases):
            time.sleep(1)
    
    # ç”Ÿæˆæ€»ä½“æŠ¥å‘Š
    generate_summary_report(overall_results)

def analyze_results(results, expected_keywords):
    """
    åˆ†ææ£€ç´¢ç»“æœçš„è´¨é‡
    
    Args:
        results: æ£€ç´¢ç»“æœåˆ—è¡¨
        expected_keywords: æœŸæœ›çš„å…³é”®è¯åˆ—è¡¨
        
    Returns:
        dict: åˆ†æç»“æœ
    """
    analysis = {
        'total_results': len(results),
        'individual_scores': [],
        'matched_keywords': [],
        'missing_keywords': [],
        'relevance_score': 0,
        'keyword_match_rate': 0
    }
    
    # åˆ†ææ¯ä¸ªç»“æœçš„ç›¸å…³æ€§
    total_score = 0
    matched_keywords_set = set()
    
    for result in results:
        result_lower = result.lower()
        score = 0
        result_matched_keywords = []
        
        # æ£€æŸ¥å…³é”®è¯åŒ¹é…
        for keyword in expected_keywords:
            if keyword in result_lower:
                score += 2
                result_matched_keywords.append(keyword)
                matched_keywords_set.add(keyword)
        
        # åŸºäºå†…å®¹é•¿åº¦å’Œç»“æ„ç»™é¢å¤–åˆ†æ•°
        if len(result.strip()) > 10:  # æœ‰å®é™…å†…å®¹
            score += 1
        if any(char in result for char in ['ğŸŸ¥', '|', 'Â·']):  # åŒ…å«æ ¼å¼åŒ–æ ‡è®°
            score += 0.5
            
        # é™åˆ¶æœ€é«˜åˆ†ä¸º10åˆ†
        score = min(score, 10)
        analysis['individual_scores'].append(score)
        total_score += score
    
    # è®¡ç®—å¹³å‡ç›¸å…³æ€§è¯„åˆ†
    if results:
        analysis['relevance_score'] = total_score / len(results)
    
    # è®¡ç®—å…³é”®è¯åŒ¹é…ç‡
    analysis['matched_keywords'] = list(matched_keywords_set)
    analysis['missing_keywords'] = [kw for kw in expected_keywords if kw not in matched_keywords_set]
    analysis['keyword_match_rate'] = (len(matched_keywords_set) / len(expected_keywords)) * 100
    
    return analysis

def generate_summary_report(results):
    """
    ç”Ÿæˆæ€»ä½“åˆ†ææŠ¥å‘Š
    """
    print("\n" + "=" * 80)
    print("ğŸ“Š æ€»ä½“åˆ†ææŠ¥å‘Š")
    print("=" * 80)
    
    if not results:
        print("âŒ æ²¡æœ‰å¯åˆ†æçš„ç»“æœ")
        return
    
    # è®¡ç®—å¹³å‡æŒ‡æ ‡
    avg_response_time = sum(r['response_time'] for r in results) / len(results)
    avg_relevance = sum(r['relevance_score'] for r in results) / len(results)
    avg_keyword_match = sum(r['keyword_match_rate'] for r in results) / len(results)
    
    print(f"ğŸ” æµ‹è¯•æŸ¥è¯¢æ•°é‡: {len(results)}")
    print(f"â±ï¸  å¹³å‡å“åº”æ—¶é—´: {avg_response_time:.2f}ç§’")
    print(f"ğŸ“ˆ å¹³å‡ç›¸å…³æ€§è¯„åˆ†: {avg_relevance:.1f}/10")
    print(f"ğŸ¯ å¹³å‡å…³é”®è¯åŒ¹é…ç‡: {avg_keyword_match:.1f}%")
    
    # æ€§èƒ½è¯„ä¼°
    print(f"\nğŸ“‹ æ€§èƒ½è¯„ä¼°:")
    if avg_response_time < 3:
        print("âœ… å“åº”é€Ÿåº¦: ä¼˜ç§€ (< 3ç§’)")
    elif avg_response_time < 6:
        print("ğŸŸ¡ å“åº”é€Ÿåº¦: è‰¯å¥½ (3-6ç§’)")
    else:
        print("ğŸ”´ å“åº”é€Ÿåº¦: éœ€è¦ä¼˜åŒ– (> 6ç§’)")
        
    if avg_relevance >= 7:
        print("âœ… ç›¸å…³æ€§: ä¼˜ç§€ (â‰¥ 7åˆ†)")
    elif avg_relevance >= 5:
        print("ğŸŸ¡ ç›¸å…³æ€§: è‰¯å¥½ (5-7åˆ†)")
    else:
        print("ğŸ”´ ç›¸å…³æ€§: éœ€è¦æ”¹è¿› (< 5åˆ†)")
        
    if avg_keyword_match >= 70:
        print("âœ… å…³é”®è¯åŒ¹é…: ä¼˜ç§€ (â‰¥ 70%)")
    elif avg_keyword_match >= 50:
        print("ğŸŸ¡ å…³é”®è¯åŒ¹é…: è‰¯å¥½ (50-70%)")
    else:
        print("ğŸ”´ å…³é”®è¯åŒ¹é…: éœ€è¦æ”¹è¿› (< 50%)")
    
    # è¯¦ç»†ç»“æœ
    print(f"\nğŸ“ è¯¦ç»†ç»“æœ:")
    for i, result in enumerate(results, 1):
        print(f"  {i}. '{result['query']}'")
        print(f"     ç›¸å…³æ€§: {result['relevance_score']:.1f}/10, "
              f"åŒ¹é…ç‡: {result['keyword_match_rate']:.1f}%, "
              f"å“åº”æ—¶é—´: {result['response_time']:.2f}ç§’")

if __name__ == "__main__":
    analyze_retrieval_quality()
