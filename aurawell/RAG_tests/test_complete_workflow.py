#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
å®Œæ•´çš„RAGå·¥ä½œæµç¨‹æµ‹è¯•
æµ‹è¯•ä»æ–‡æ¡£ä¸Šä¼ åˆ°æ£€ç´¢çš„å®Œæ•´æµç¨‹ï¼ŒéªŒè¯å¼•ç”¨è¿‡æ»¤åŠŸèƒ½çš„æ•ˆæœ
"""

import sys
import os

# æ·»åŠ çˆ¶ç›®å½•åˆ°Pythonè·¯å¾„ï¼Œä»¥ä¾¿å¯¼å…¥ragæ¨¡å—
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
rag_dir = os.path.join(parent_dir, 'rag')
sys.path.insert(0, rag_dir)

from RAGExtension import Document, UserRetrieve
import time

def test_complete_rag_workflow():
    """
    æµ‹è¯•å®Œæ•´çš„RAGå·¥ä½œæµç¨‹
    """
    print("=" * 80)
    print("å®Œæ•´RAGå·¥ä½œæµç¨‹æµ‹è¯•ï¼ˆåŒ…å«å¼•ç”¨è¿‡æ»¤ï¼‰")
    print("=" * 80)
    
    # ç¬¬ä¸€æ­¥ï¼šæ–‡æ¡£ä¸Šä¼ å’Œå‘é‡åŒ–
    print("ğŸ”„ ç¬¬ä¸€æ­¥ï¼šæ–‡æ¡£è§£æå’Œå‘é‡åŒ–ï¼ˆè¿‡æ»¤å¼•ç”¨ï¼‰")
    print("-" * 60)
    
    try:
        doc = Document()
        sample_doc_path = os.path.join("..", "rag", "testMaterials", "ä¸­å›½æˆå¹´äººè‚‰ç±»é£Ÿç‰©æ‘„å…¥ä¸ä»£è°¢ç»¼åˆå¾çš„ç›¸å…³æ€§ç ”ç©¶.pdf")
        
        print(f"ğŸ“„ å¤„ç†æ–‡æ¡£: {sample_doc_path}")
        
        start_time = time.time()
        result = doc.file2VectorDB(sample_doc_path)
        upload_time = time.time() - start_time
        
        if result:
            print(f"âœ… æ–‡æ¡£ä¸Šä¼ æˆåŠŸï¼Œè€—æ—¶: {upload_time:.2f}ç§’")
        else:
            print("âŒ æ–‡æ¡£ä¸Šä¼ å¤±è´¥")
            return False
            
    except Exception as e:
        print(f"âŒ æ–‡æ¡£ä¸Šä¼ è¿‡ç¨‹å‡ºé”™: {e}")
        return False
    
    # ç­‰å¾…ä¸€ä¸‹ç¡®ä¿æ•°æ®å·²ç»å†™å…¥
    print("â³ ç­‰å¾…æ•°æ®å†™å…¥å®Œæˆ...")
    time.sleep(3)
    
    # ç¬¬äºŒæ­¥ï¼šç”¨æˆ·æŸ¥è¯¢æ£€ç´¢
    print(f"\nğŸ” ç¬¬äºŒæ­¥ï¼šç”¨æˆ·æŸ¥è¯¢æ£€ç´¢æµ‹è¯•")
    print("-" * 60)
    
    try:
        retriever = UserRetrieve()
        
        # æµ‹è¯•æŸ¥è¯¢åˆ—è¡¨
        test_queries = [
            {
                "query": "æ¯æ—¥è¥å…»å»ºè®®",
                "description": "æ—¥å¸¸è¥å…»æ‘„å…¥æŒ‡å¯¼"
            },
            {
                "query": "è¿åŠ¨åçš„è¥å…»è¡¥å……å»ºè®®", 
                "description": "è¿åŠ¨è¥å…»è¡¥å……"
            },
            {
                "query": "é«˜è¡€å‹é«˜è¡€è„‚çš„é¥®é£Ÿå»ºè®®",
                "description": "å¿ƒè¡€ç®¡ç–¾ç—…é¥®é£Ÿ"
            }
        ]
        
        all_results = []
        
        for i, test_case in enumerate(test_queries, 1):
            query = test_case["query"]
            description = test_case["description"]
            
            print(f"\nğŸ“‹ æŸ¥è¯¢ {i}: {description}")
            print(f"ğŸ” æŸ¥è¯¢å†…å®¹: '{query}'")
            
            start_time = time.time()
            results = retriever.retrieve_topK(query, k=5)
            query_time = time.time() - start_time
            
            print(f"â±ï¸  æŸ¥è¯¢è€—æ—¶: {query_time:.2f}ç§’")
            print(f"ğŸ“Š æ£€ç´¢åˆ° {len(results)} ä¸ªç›¸å…³å†…å®¹")
            
            # æ£€æŸ¥ç»“æœè´¨é‡
            reference_count = 0
            relevant_count = 0
            
            print(f"\nğŸ“ æ£€ç´¢ç»“æœ:")
            for j, result in enumerate(results, 1):
                # æ£€æŸ¥æ˜¯å¦ä¸ºå¼•ç”¨
                is_reference = doc._Document__is_reference_content(result)
                
                if is_reference:
                    reference_count += 1
                    status = "ğŸ“š [å¼•ç”¨]"
                else:
                    relevant_count += 1
                    status = "ğŸ“„ [å†…å®¹]"
                
                # æ£€æŸ¥ç›¸å…³æ€§ï¼ˆç®€å•å…³é”®è¯åŒ¹é…ï¼‰
                query_lower = query.lower()
                result_lower = result.lower()
                
                relevance_keywords = []
                if "è¥å…»" in query_lower and "è¥å…»" in result_lower:
                    relevance_keywords.append("è¥å…»")
                if "è¿åŠ¨" in query_lower and "è¿åŠ¨" in result_lower:
                    relevance_keywords.append("è¿åŠ¨")
                if "è¡€å‹" in query_lower and "è¡€å‹" in result_lower:
                    relevance_keywords.append("è¡€å‹")
                if "é¥®é£Ÿ" in query_lower and ("é¥®é£Ÿ" in result_lower or "é£Ÿ" in result_lower):
                    relevance_keywords.append("é¥®é£Ÿ")
                
                relevance_score = len(relevance_keywords)
                
                display_text = result[:80] + "..." if len(result) > 80 else result
                print(f"  {j}. {status} [ç›¸å…³æ€§: {relevance_score}] {display_text}")
            
            # ç»Ÿè®¡ç»“æœè´¨é‡
            quality_score = (relevant_count / len(results)) * 100 if results else 0
            
            print(f"\nğŸ“ˆ ç»“æœè´¨é‡åˆ†æ:")
            print(f"   æœ‰æ•ˆå†…å®¹: {relevant_count}/{len(results)} ({quality_score:.1f}%)")
            print(f"   å¼•ç”¨å†…å®¹: {reference_count}/{len(results)} ({(reference_count/len(results)*100) if results else 0:.1f}%)")
            
            all_results.append({
                "query": query,
                "results_count": len(results),
                "relevant_count": relevant_count,
                "reference_count": reference_count,
                "query_time": query_time,
                "quality_score": quality_score
            })
            
            if i < len(test_queries):
                print("â³ ç­‰å¾…2ç§’åè¿›è¡Œä¸‹ä¸€ä¸ªæŸ¥è¯¢...")
                time.sleep(2)
        
        # ç¬¬ä¸‰æ­¥ï¼šæ€»ä½“è¯„ä¼°
        print(f"\nğŸ“Š ç¬¬ä¸‰æ­¥ï¼šæ€»ä½“æ€§èƒ½è¯„ä¼°")
        print("-" * 60)
        
        total_queries = len(all_results)
        avg_query_time = sum(r["query_time"] for r in all_results) / total_queries
        avg_quality = sum(r["quality_score"] for r in all_results) / total_queries
        total_references = sum(r["reference_count"] for r in all_results)
        total_results = sum(r["results_count"] for r in all_results)
        
        print(f"ğŸ” æ€»æŸ¥è¯¢æ•°: {total_queries}")
        print(f"â±ï¸  å¹³å‡æŸ¥è¯¢æ—¶é—´: {avg_query_time:.2f}ç§’")
        print(f"ğŸ“ˆ å¹³å‡å†…å®¹è´¨é‡: {avg_quality:.1f}%")
        print(f"ğŸ“š å¼•ç”¨è¿‡æ»¤æ•ˆæœ: {total_references}/{total_results} ä¸ªç»“æœä¸ºå¼•ç”¨å†…å®¹")
        
        # æ€§èƒ½è¯„çº§
        print(f"\nğŸ† ç³»ç»Ÿæ€§èƒ½è¯„çº§:")
        
        if avg_query_time < 3:
            print("âœ… æŸ¥è¯¢é€Ÿåº¦: ä¼˜ç§€ (< 3ç§’)")
        elif avg_query_time < 6:
            print("ğŸŸ¡ æŸ¥è¯¢é€Ÿåº¦: è‰¯å¥½ (3-6ç§’)")
        else:
            print("ğŸ”´ æŸ¥è¯¢é€Ÿåº¦: éœ€è¦ä¼˜åŒ– (> 6ç§’)")
        
        if avg_quality >= 80:
            print("âœ… å†…å®¹è´¨é‡: ä¼˜ç§€ (â‰¥ 80%)")
        elif avg_quality >= 60:
            print("ğŸŸ¡ å†…å®¹è´¨é‡: è‰¯å¥½ (60-80%)")
        else:
            print("ğŸ”´ å†…å®¹è´¨é‡: éœ€è¦æ”¹è¿› (< 60%)")
        
        reference_ratio = (total_references / total_results) * 100 if total_results > 0 else 0
        if reference_ratio < 10:
            print("âœ… å¼•ç”¨è¿‡æ»¤: ä¼˜ç§€ (< 10%å¼•ç”¨å†…å®¹)")
        elif reference_ratio < 20:
            print("ğŸŸ¡ å¼•ç”¨è¿‡æ»¤: è‰¯å¥½ (10-20%å¼•ç”¨å†…å®¹)")
        else:
            print("ğŸ”´ å¼•ç”¨è¿‡æ»¤: éœ€è¦æ”¹è¿› (> 20%å¼•ç”¨å†…å®¹)")
        
        return True
        
    except Exception as e:
        print(f"âŒ æŸ¥è¯¢æ£€ç´¢è¿‡ç¨‹å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    print("å¼€å§‹å®Œæ•´RAGå·¥ä½œæµç¨‹æµ‹è¯•...")
    
    success = test_complete_rag_workflow()
    
    print("\n" + "=" * 80)
    if success:
        print("ğŸ‰ å®Œæ•´RAGå·¥ä½œæµç¨‹æµ‹è¯•æˆåŠŸå®Œæˆï¼")
        print("âœ… å¼•ç”¨è¿‡æ»¤åŠŸèƒ½æ­£å¸¸å·¥ä½œ")
        print("âœ… æ–‡æ¡£è§£æå’Œå‘é‡åŒ–åŠŸèƒ½æ­£å¸¸")
        print("âœ… ç”¨æˆ·æŸ¥è¯¢æ£€ç´¢åŠŸèƒ½æ­£å¸¸")
    else:
        print("âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯")
    print("=" * 80)
